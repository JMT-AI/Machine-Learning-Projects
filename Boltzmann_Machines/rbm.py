# Restricted Boltzmann Machine# --------------------------- Jean-Martial Tagro# -------------------------------------------------------------------------# SYSTEME DE RECOMMANDATION DE FILM via une Machine de Boltzmann Resteinte# -------------------------------------------------------------------------# Librairiesimport pandas as pdimport numpy as npimport torch # pythorch libraryimport torch.nn as nnimport torch.nn.parallel as parallelimport torch.optim as optimimport torch.utils.datafrom torch.autograd import Variable# --------------------------# PART 1 : DATA PREPARATION | # --------------------------# Importation donnéesmovies = pd.read_csv('ml-1m/movies.dat', sep='::',                      header=None,                     engine='python',                     encoding='latin-1')users = pd.read_csv('ml-1m/users.dat', sep='::',                      header=None,                     engine='python',                     encoding='latin-1')ratings = pd.read_csv('ml-1m/ratings.dat', sep='::',                      header=None,                     engine='python',                     encoding='latin-1')# Train and Test Split - 1st with 100k notestraining_set = pd.read_csv('ml-100k/u1.base', delimiter='\t', header=None)training_set = np.array(training_set, dtype='int')test_set = pd.read_csv('ml-100k/u1.test', delimiter='\t', header=None)test_set = np.array(test_set, dtype='int')# Construction de la Matrice pour le système de recommandation# ------------------------------------------------------------ # Obtention du nombre de users et du nombre de filmsnb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))def convert(data):    """ Conversion des donneés en matrice    Pour chaque user, on affiche en 'features' les notes de     tous les films vu ou non    """    new_data = []        for id_user in range(1, nb_users + 1):                id_movies_seen  = data[data[:,0] == id_user, 1] #filtrage        ratings_given   = data[data[:,0] == id_user, 2] #filtrage                # creation de la liste de tous les movies avec notes du user        user_ratings                     = np.zeros(nb_movies)        user_ratings[id_movies_seen - 1] = ratings_given                   new_data.append(list(user_ratings))            return new_datamatrix_train = convert(training_set)matrix_test = convert(test_set)    # Conversion des data en type 'tensor' pour pytorch#--------------------------------------------------matrix_train = torch.FloatTensor(matrix_train) matrix_test = torch.FloatTensor(matrix_test) # Recommandation binaire : remplacement des notes '0' (pas vu le film) en -1matrix_train[matrix_train == 0] = -1matrix_test[matrix_test == 0] = -1# Conversion en classification binaire, avec comme SEUIL = 3matrix_train[matrix_train == 1] = 0matrix_train[matrix_train == 2] = 0matrix_train[matrix_train >= 3] = 1matrix_test[matrix_test == 1] = 0matrix_test[matrix_test == 2] = 0matrix_test[matrix_test >= 3] = 1# --------------------------# PART 2 : RECOMMANDATIONS  |  Recommendation binaire (J'aime) ou (Je n'aime pas)# --------------------------# CONSTRUCTION DE L"ARCHITECTURE DU RBMclass RBM():        def __init__(self, nv, nh):   # nv = nb_neuron_visible, nh = nb_neuron_hidden                        self.W = torch.randn(nh, nv) # matrice de poids        self.b = torch.randn(1, nh)  # vecteur de biais des neurones cachés / need 1 sup dim        self.a = torch.randn(1, nv)  # vecteur de biais des neurones visibles / idem                " Markov chain Monte Carlo"        # Echantillonnage de Gibbs : calcul nodes cachés    def sample_h(self, x):        wx = torch.mm(x, self.W.t()) # prod matriciel        value = wx + self.a.expand_as(wx) # biais with several rows (batch)        p_h_given_v = torch.sigmoid(value)                return p_h_given_v, torch.bernoulli(p_h_given_v) # loi de bernouilli [0,1]                    # Echantillonnage de Gibbs : calcul nodes visibles     def sample_v(self, y):        wy = torch.mm(y, self.W) # prod matriciel        value = wy + self.a.expand_as(wy) # biais with several rows (batch)        p_v_given_h = torch.sigmoid(value)                return p_v_given_h, torch.bernoulli(p_v_given_h) # loi de bernouilli [0,1]        def train(self, v0, vk, ph0, phk): # Mise à jour poids - see pdf for details        self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)        self.b += torch.sum((v0 - vk), 0) # avoid v0 - vk to keep dimension        self.a += torch.sum((ph0 - phk), 0)        nv = matrix_test.shape[1] # nb de moviesnh = 100 # to test ...batch_size = 100# Creation de la RBMrbm = RBM(nv, nh)# Entrainement de la RBMnb_epoch = 10for epoch in range(1, nb_epoch + 1):    train_loss = 0    s = 0.    for id_user in range(0, nb_users - batch_size, batch_size):        v0 = matrix_train[id_user : id_user + batch_size]        vk = v0        ph0, _ = rbm.sample_h(v0)        print('ok')                for k in range(10): # 10 iterations Gibbs sampling            _, hk  = rbm.sample_h(vk)            _, vk  = rbm.sample_v(hk)            vk[v0 < 0] = v0[v0 < 0]                    phk, _ = rbm.sample_h(vk)                    rbm.train(v0, vk, ph0, phk)                train_loss += torch.mean(torch.abs(vk[v0 >= 0] - vk[v0 >= 0]))        s += 1.            print('Epoch : {} / Loss : {}'.format(epoch, train_loss / s))          #########################      # Prediction sur le jeu de test (prediction des nouvelles valeurs des '-1') --> non-vustest_loss = 0compteur = 0.for id_user in range(0, nb_users):    v = matrix_test[id_user]    vt = v        if(len(vt[vt >= 0] > 0)):        _, h  = rbm.sample_h(v)        _, v  = rbm.sample_v(h)        # Distance absolue moyenne -- pouvait use RMSE aussi    test_loss += torch.mean(torch.abs(vt[vt >= 0] - v[vt >= 0]))    compteur += 1.            print('Loss : {}'.format(test_loss / compteur))