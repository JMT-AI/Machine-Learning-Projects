{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='steelblack'>\n",
    "    <h1 align=center> Implementation du VGG-16 et mise en oeuvre du Transfert Learning <br><br>pour la Computer Vision</h1>\n",
    "          </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=center>CentraleSupélec-OpenClassrooms Certifiyng Training</h2>\n",
    "\n",
    "<h3 align=center>Jean Martial Tagro </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet de notre étude est VGG-16, une version du réseau de neurones convolutif très connu appelé VGG-Net. Nous allons d'abord l'implémenter de A à Z pour découvrir Keras, puis nous allons voir comment classifier des images de manière efficace. Pour cela, nous allons exploiter le réseau VGG-16 pré-entraîné fourni par Keras, et mettre en oeuvre le Transfer Learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Architecture de VGG-16\n",
    "\n",
    "\n",
    "![title](vgg_16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implémentation de VGG-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installons préalablement le module keras dans notre environnement. Ça déjà été fait et le noyau relancé, d'où la mise en commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%conda install keras # IMPORTANT : Just need to execute once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importations\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, MaxPool2D, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETAPE 1 : initialisation\n",
    "my_VGG16 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG built successfully !\n"
     ]
    }
   ],
   "source": [
    "my_VGG16.add(Reshape((224, 224, 3))) # IMPORTANT To reshape before Conv Layer\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ETAPE 2 : Ajout 1ere couche de CONVOLUTION suivie d'une ReLU       |\n",
    "# --------------------------------------------------\n",
    "\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    input_shape = (224, 224, 3),\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 3 : Ajout de la 2e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ETAPE 4 : Ajout d'une 1ere couche de Pooling       |\n",
    "# ----------------------------------------------\n",
    "my_VGG16.add(MaxPool2D(pool_size = (2,2))) # Default : Strides = pool_size\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ETAPE 5 : Ajout d'une 3e couche de CONVOLUTION suivie d'une ReLU       |\n",
    "# --------------------------------------------------\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 6 : Ajout de la 4e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ETAPE 7 : Ajout d'une 2e couche de Pooling       |\n",
    "# ----------------------------------------------\n",
    "my_VGG16.add(MaxPool2D(pool_size = (2,2))) # Default : Strides = pool_size\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 8 : Ajout de la 5e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\\\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 9 : Ajout de la 6e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 10 : Ajout de la 7e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ETAPE 11 : Ajout d'une 3e couche de Pooling       |\n",
    "# ----------------------------------------------\n",
    "my_VGG16.add(MaxPool2D(pool_size = (2,2))) # Default : Strides = pool_size\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 12 : Ajout de la 8e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\\\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 13 : Ajout de la 9e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 14 : Ajout de la 10e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ETAPE 15 : Ajout d'une 4e couche de Pooling       |\n",
    "# ----------------------------------------------\n",
    "my_VGG16.add(MaxPool2D(pool_size = (2,2))) # Default : Strides = pool_size\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 16 : Ajout de la 11e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\\\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 17 : Ajout de la 12e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ETAPE 18 : Ajout de la 13e couche de CONVOLUTION suivie d'une ReLU  |\n",
    "# ----------------------------------------------------------------\n",
    "my_VGG16.add(Conv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3, # means (3,3) shape\n",
    "    #strides = 1,\n",
    "    padding = 'same', # keep shape after convolution layer\n",
    "    activation = 'relu'))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# ETAPE 15 : Ajout d'une 5e couche de Pooling       |\n",
    "# ----------------------------------------------\n",
    "my_VGG16.add(MaxPool2D(pool_size = (2,2))) # Default : Strides = pool_size\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ETAPE 4 : FLATTENING         |\n",
    "# -----------------------------\n",
    "my_VGG16.add(Flatten()) # Conversion des matrices 3D en vecteur 1D\n",
    "\n",
    "# ------------------------------\n",
    "# ETAPE 5 : Full connected layers|\n",
    "# ------------------------------\n",
    "my_VGG16.add(Dense(units = 4096, activation = 'relu'))\n",
    "my_VGG16.add(Dense(units = 4096, activation = 'relu'))\n",
    "my_VGG16.add(Dense(units = 1000, activation = 'softmax')) # 1000 classes to predict\n",
    "\n",
    "# ------------------------------\n",
    "# ETAPE 6 : COMPILATION         |\n",
    "# ------------------------------\n",
    "my_VGG16.compile(optimizer = 'adam',\n",
    "                   loss = 'categorical_crossentropy', # binary_crossentropy for 2 classes\n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "# for confirmation\n",
    "print('VGG built successfully !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Utilisation du VGG-16 pré-entraîné"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons apprendre à classifier des images avec le modèle VGG-16 fourni par Keras et pré-entraîné sur ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 279s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "model_VGG16 = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, le constructeur  VGG16()  crée le réseau VGG-16 pré-entraîné sur le jeu d'images <strong>ImageNet</strong>. Si à l'avenir, pour d'autres projets, vous souhaitez initialiser aléatoirement les poids, il faudra préciser  weight=None  en argument.\n",
    "\n",
    "Le constructeur possède d'autres paramètres pour faire du Transfer Learning, que nous allons utiliser dans la partie suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser ce réseau pré-entraîné pour classer une image dans une des 1000 catégories d'ImageNet.\n",
    "\n",
    "Nous devons d'abord charger l'image et la pré-traiter afin qu'elle respecte bien les spécifications des images en entrée de VGG-16. Pour cela, nous allons utiliser les fonctions du module  keras.preprocessing.image  et  keras.preprocessing.vgg16  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load image\n",
    "test_image = image.load_img('cat_or_dog_4.jpg', target_size=(224, 224))\n",
    "\n",
    "# convert image to array\n",
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "# add 1 dim for group at 1st position\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "#test_image = test_image.reshape((1, test_image.shape[0], test_image.shape[1], test_image.shape[2]))  # Créer la collection d'images (un seul échantillon)\n",
    "\n",
    "# Prétraiter l'image comme le veut VGG-16\n",
    "test_image = preprocess_input(test_image)  \n",
    "\n",
    "# \n",
    "result_vector = model_VGG16.predict(test_image)\n",
    "\n",
    "result_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 : [('n02124075', 'Egyptian_cat', 0.47407573), ('n02127052', 'lynx', 0.11349619), ('n02123597', 'Siamese_cat', 0.078486316)]\n"
     ]
    }
   ],
   "source": [
    "# Afficher les 3 classes les plus probables\n",
    "print('Top 3 :', decode_predictions(result_vector, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la section précédente, on a utilisé le réseau VGG-16 fourni par Keras pour résoudre le même problème de classification que celui sur lequel il a été pré-entraîné (classification à 1000 classes avec ImageNet). En pratique, on est très probablement confrontés à un nouveau problème de classification. Dans ce cas, savoir mettre en oeuvre le Transfer Learning est très utile ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Récupérer la sortie de ce réseau\n",
    "x = model.outputs\n",
    "\n",
    "# Ajouter la nouvelle couche fully-connected pour la classification à 10 classes\n",
    "#predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "#new_model_VGG16 = model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stratégie 1 : fine-tuning total : Ici, on entraîne tout le réseau, donc il faut rendre toutes les couches \"entraînables\" :\n",
    "for layer in model.layers:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratégie 2 : extraction de features\n",
    "# On entraîne seulement le nouveau classifieur et on ne ré-entraîne pas les autres couches :\n",
    "for layer in model.layers:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratégie #3 : fine-tuning partiel\n",
    "#On entraîne le nouveau classifieur et les couches hautes :\n",
    "# Ne pas entraîner les 5 premières couches (les plus basses) \n",
    "for layer in model.layers[:5]:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation + Entraînement du réseau\n",
    "\n",
    "# Compiler le modèle \n",
    "# new_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "# model_info = new_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
